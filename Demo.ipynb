{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.getcwd()\n",
    "data_path = os.path.join(root_path, \"Data\")\n",
    "\n",
    "train_path = os.path.join(data_path, \"train_set.json\")\n",
    "test_path = os.path.join(data_path, \"test_set.json\")\n",
    "documents_path = os.path.join(data_path, \"documents.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open(train_path)\n",
    "train_set = json.load(f)\n",
    "f = open(test_path)\n",
    "test_set = json.load(f)\n",
    "f = open(documents_path)\n",
    "documents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(train_path)\n",
    "test_df = pd.read_json(test_path)\n",
    "documents_df = pd.read_json(documents_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two GOP presidential hopefuls - Ted Cruz and B...</td>\n",
       "      <td>Ted Cruz and Ben Carson want the charity to re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Tesla Model S P85D's 'insane mode' may be ...</td>\n",
       "      <td>latvia-based drive eo has created a vehicle, n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI5 has issued an alert over the threat posed ...</td>\n",
       "      <td>Alert issued over rogue workers in nuclear , t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A new video that shows homeless people reading...</td>\n",
       "      <td>A short film highlights the nasty things peopl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aston Villa may be gearing up for an FA Cup se...</td>\n",
       "      <td>tim sherwood replied to a letter from charlie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  Two GOP presidential hopefuls - Ted Cruz and B...   \n",
       "1  The Tesla Model S P85D's 'insane mode' may be ...   \n",
       "2  MI5 has issued an alert over the threat posed ...   \n",
       "3  A new video that shows homeless people reading...   \n",
       "4  Aston Villa may be gearing up for an FA Cup se...   \n",
       "\n",
       "                                             summary  label  \n",
       "0  Ted Cruz and Ben Carson want the charity to re...      1  \n",
       "1  latvia-based drive eo has created a vehicle, n...      0  \n",
       "2  Alert issued over rogue workers in nuclear , t...      1  \n",
       "3  A short film highlights the nasty things peopl...      1  \n",
       "4  tim sherwood replied to a letter from charlie ...      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Shelling hit areas near two key citie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There aren't many NFL players who influenced t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Work has got under way to repaint the striking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(CNN) -- American Presidents have come and gon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Jessie Roach is 31 years old and has mental di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document\n",
       "0     (CNN) -- Shelling hit areas near two key citie...\n",
       "1     There aren't many NFL players who influenced t...\n",
       "10    Work has got under way to repaint the striking...\n",
       "100   (CNN) -- American Presidents have come and gon...\n",
       "1000  Jessie Roach is 31 years old and has mental di..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Train set.json**: This file contains 8000 summaries in total with (in the field summary of the json file) their original documents (in the field document of the json file) and labels (in the field label of the json file). The dataset is divided as follows: 4000 reference summaries and 4000 summaries generated from different machine summarisation systems.\n",
    "\n",
    "> - **Test set.json:** This file contains 3600 summaries in total, divided as follows: 1600 reference summaries and 1600 summaries generated using the same models used in the train set. This dataset is distributed equally between the public and private leaderboards on kaggle.\n",
    "\n",
    "> - **Documents.json:** This file contains 50000 original documents that could be useful to make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(CNN) -- Shelling hit areas near two key cities in eastern Ukraine on Sunday morning, intensifying fears that a ceasefire that took effect less than two days ago may be falling apart.\\n\\nWhy is the ceasefire under strain?\\n\\nA variety of fighting factions in the conflict zone -- on both sides -- may not fall directly under a military chain of command. The pro-Russian rebels are mostly volunteer militias; fighting against them on the Ukrainian side are at least some far-right nationalist militias. Controlling these groups is difficult and some may have different aims, including sabotaging the truce.\\n\\nAt this point it's been nearly impossible to figure out who's doing the firing and why.\\n\\nThe conditions of the ceasefire agreement don't help either. The conditions are vague and at this point there doesn't seem to be an effective mechanism in place inside the conflict zone to monitor and enforce the agreement.\\n\\nWhy can't the two sides' leaders control their forces?\\n\\nIt's unclear if Kiev has control over all of the fighting forces in eastern Ukraine. Some of the volunteer militias fighting alongside Ukrainian soldiers are far-right nationalists who've been critical of the current government in Kiev, but they're still fighting because they feel Ukraine is under attack by Russia.\\n\\nAnd who controls the pro-Russian rebels? Is it the local commanders? Is it Russian President Vladimir Putin? None of that is clear.\\n\\nWhich side has the most to gain from the truce?\\n\\nIf the truce leads to good-faith negotiations and a compromise, then both sides can gain. A compromise could look like something like this: The pro-Russian region of Donbas gets autonomy and self-determination under a federalized Ukrainian government, and in return the rebels drop their demand for independence and Kiev gets to protect Ukraine's sovereignty and territorial integrity.\\n\\nThere are elements on both sides that don't want a compromise, and they could certainly have the potential of undermining the truce.\\n\\nWhat happens next?\\n\\nWe wait to see if the overnight shellings and firings are an anomaly or if they're a sign of more violence and more fighting. If the ceasefire sticks, both sides have agreed to hold talks that will address the core issues and demands on both sides that are still unresolved -- including the disarming of the rebels, a guarantee of self-determination for the pro-Russian Donbas region, the fate of Russian-annexed Crimea, constitutional reform, and a solution to the humanitarian crisis in the conflict zone.\\n\\nObviously if the fighting continues, all bets are off.\\n\\nWhat effect does this have on the rest of the world?\\n\\nWhat happens in the coming days will determine the next move by NATO and Western leaders. If the ceasefire falls apart, the West will likely turn up the pressure by following through with sanctions and bolstering Western forces in NATO's Baltic-member states. Moscow has already threatened to respond if that happens. The bottom line is, the conflict will escalate and so will the prospects of a regional conflict -- although at this point that seems unlikely.\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df[\"document\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Two GOP presidential hopefuls - Ted Cruz and Ben Carson - want the Clinton Foundation to return every dollar its received from foreign governments since it launched more than a decade ago.\\n\\nThe bum rush on the non-profit came about after a report cast a new shadow over the charity's fundraising practices while Hillary Clinton served as the United State's chief diplomat.\\n\\nA Reuters investigation that revealed the Bill, Hillary and Chelsea Clinton Foundation had misreported millions of dollars in donations from foreign nations led the global charity to announce that it would refile more than five years of tax documents.\\xa0\\n\\nScroll down for video\\xa0\\n\\nA Reuters investigation that revealed the Bill, Hillary and Chelsea Clinton Foundation had misreported millions of dollars in donations from foreign nations led the global charity to announce that it would refile more than five years of tax documents - Republicans pounced\\n\\nThe discovery came as separate financial reviews found that previously unreported foreign businesses either donated money directly to the family foundation or paid Bill to speak while their countries were doing official business with the State Department during Hillary's tenure.\\n\\nIn one instance,  Bill Clinton received one of his biggest paychecks in $500,000 for a June 2010 speech in Moscow funded by an investment bank with ties to Russian President Vladimir Putin.\\n\\nThe Clinton Foundation was barred by an agreement from accepting money from foreign governments it wasn't already in business while Mrs. Clinton was in President Barack Obama's cabinet.\\xa0\\n\\nBut that didn't stop it from doing so anyway. It fessed up in February to accepting a $500,000 donation from Algeria in 2010 without telling the State Department.\\n\\nAnd the agreement is not known to have put restraints on Mr. Clinton's ability to collect paychecks from foreign actors.\\n\\nTaking aim at Hillary Clinton, Cruz said in a Wednesday evening Facebook, 'Having raised tens of millions of dollars from foreign nations presents a clear conflict of interest for anyone running for President of the United States.'\\n\\n'Add your name if you agree Hillary Clinton should return all money raised from foreign nations!' the Texas senator added,\\xa0soliciting names for a petition urging the non-profit to give back the funds.\\n\\nCarson told Daily Mail Online today that he, too, believes the charity cough up the cash.\\n\\n'It is my strong belief that not only should they definitely give back the money and cease accepting foreign donations, but should also make every effort to find missing documents that would shed light if in fact they are innocent,' he said..\\n\\nTwo GOP presidential hopefuls - Ted Cruz, left, and Ben Carson, right - want the Clinton Foundation to return every dollar its received from foreign governments since it launched more than a decade ago\\n\\n'It's the Clinton way: raking in millions from foreign governments behind closed doors while making promises about transparency that they never intended to keep,' former business executive Carly Fiorina wrote on Facebook. 'Now they're scrambling to refile their taxes and account for her decisions as Secretary of State.'\\n\\nAfter Clinton made official her candidacy for the Oval Office, the foundation said it would impose a moratorium on checks from foreign governments that it's not already partnered with - but it still plans to take money from governments it has recently done work with.\\n\\nCarson, who is expected to jump into the 2016 race on May 4, said in his statement that 'one of the things that has become clear' in his travels across the country 'is that the American people are sick of corruption and dishonesty within the government.'\\n\\n'Doublespeak and redefining terms to fit a narrative is truly unacceptable and misleading. The Clinton Foundation and the appearance of wrongdoing reinforces these feelings,' the retired neurosurgeon and tea party icon said.\\n\\n'Anyone who contemplates a leadership position in our great nation should thoroughly examine their motives to determine if they are simply interested in enriching themselves and enhancing their own power versus strengthening America and passing it on to the next generation in an improved and ethical condition,' he posited.\\xa0\\n\\n'Add your name if you agree Hillary Clinton should return all money raised from foreign nations!' Ted Cruz said in a Facebook post soliciting names for a petition urging the non-profit to give back the funds\\n\\nFormer business executive Carly Fiorina, who will reportedly announce her own candidacy the same day as Carson via social media, stopped short of demanding that the Clinton Foundation start writing checks for money it likely doesn't have in the bank if they were cashed.\\n\\nShe did use the opportunity to levy an attack on Clinton, however, whom she's positioned herself next to in the field as an alternative to for voters looking to break the glass ceiling by electing a woman president.\\n\\n'It's the Clinton way: raking in millions from foreign governments behind closed doors while making promises about transparency that they never intended to keep,' Fiorina wrote on Facebook. 'Now they're scrambling to refile their taxes and account for her decisions as Secretary of State.'\\n\\n'The American people will have a choice. Are we going to demand trust and transparency from our leaders? Have we had enough of a ruling political class that doles out favors to the wealthy and well connected few?' she said, previewing her stump speech.\\n\\nSouth Carolina Senator Lindsey Graham, who is testing the waters for a 2016 campaign, said, 'These stories today raise some very serious questions about the donations and relationships around the Clintons and their foundation.'\\n\\n'I believe Secretary Clinton owes the public some answers about any potential impropriety,' he told Daily Mail Online.\\n\\nCOZY: Bill Clinton is seen here shaking the hand the then Prime Minister of Russia Vladimir Putin, now the president of the country who the U.S. has a complicated relationship with, June 29, 2010. The former U.S. president received one of his biggest paychecks in $500,000 for a speech in Moscow that took place during this trip and was funded by an investment bank with ties to Putin\\n\\nA new book that Republican presidential candidate Rand Paul promises will shed additional light on the non-profit's fundraising practices has had the entire 2016 field ready to pounce on Democratic front-runner Hillary Clinton for weeks.\\xa0\\n\\nPaul told Fox News' Sean Hannity on Tuesday evening that the expose's author, Peter Schweizer, had briefed him 'and the facts are going to be alarming. They're going to be mind-boggling.'\\n\\nThe Kentucky senator said he was bound to secrecy on the contents of the 186-page investigative book, Clinton Cash: The Untold Story of How and Why Foreign Governments and Businesses Helped Make Bill and Hillary Rich.'\\n\\n'But I think people are going to be blown away by the details in this book and how they link the Clintons into this enormous exchange of money from foreign countries, from donors to companies, and then it's all swirling around,' he told Hannity.\\n\\n'And I don't think it would happen if you didn't have somebody who was a secretary of state and a former president, and they seem to be capitalizing on their service in government,' he contended.\\n\\nContinuing, Paul implied that the Clintons were 'using the system to enrich themselves,' and said, 'I think it looks unseemly. And I think a lot of Americans are going to agree with me.'\\xa0\\n\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"document\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ted Cruz and Ben Carson want the charity to return every dollar its received from foreign governments since its launch in 2001 . Bum rush came about after a report cast a new shadow over the charity 's fundraising practices while Hillary Clinton was the country 's chief diplomat . Cruz said : ` Having raised tens of millions of dollars from foreign nations presents a clear conflict of interest for anyone running for President ' Carson said they ` should they definitely give back the money and cease accepting foreign donations , but should also make every effort to find missing documents that would shed light if in fact they are innocent ' Carly Fiorina said , ` It 's the Clinton way : raking in millions from foreign governments behind closed doors while making promises about transparency that they never intended to keep '\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"summary\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis & Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4000\n",
       "1    4000\n",
       "Name: summary, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Get the number of dates / entries in each month\n",
    "train_df.groupby('label')['summary'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    304.60550\n",
       "1    307.99875\n",
       "Name: character_cnt, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Character length\n",
    "\n",
    "train_df['character_cnt'] = train_df['summary'].str.len()\n",
    "train_df.groupby('label')['character_cnt'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    54.887\n",
       "1    56.925\n",
       "Name: word_counts, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['word_counts'] = train_df['summary'].str.split().str.len()\n",
    "train_df.groupby('label')['word_counts'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5.597578\n",
       "1    5.441352\n",
       "Name: characters_per_word, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['characters_per_word'] = train_df['character_cnt']/train_df['word_counts']\n",
    "train_df.groupby('label')['characters_per_word'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special character count\n",
    "train_df['spl'] = train_df['summary'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.67025\n",
       "1    0.80450\n",
       "Name: num, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of numerics\n",
    "train_df['num'] = train_df['summary'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "train_df.groupby('label')['num'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_cnt</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>characters_per_word</th>\n",
       "      <th>spl</th>\n",
       "      <th>num</th>\n",
       "      <th>processedtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>833</td>\n",
       "      <td>146</td>\n",
       "      <td>5.705479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ted cruz ben carson want chariti return everi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>362</td>\n",
       "      <td>65</td>\n",
       "      <td>5.569231</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>latviabas drive eo creat vehicl name eo pp03 r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>5.518519</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>alert issu rogu worker nuclear transport publi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>44</td>\n",
       "      <td>5.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a short film highlight nasti thing peopl say h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>48</td>\n",
       "      <td>5.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tim sherwood repli letter charli pye tuesday p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character_cnt  word_counts  characters_per_word  spl  num  \\\n",
       "0            833          146             5.705479    0    1   \n",
       "1            362           65             5.569231    0    3   \n",
       "2            298           54             5.518519    0    1   \n",
       "3            221           44             5.022727    0    0   \n",
       "4            262           48             5.458333    0    0   \n",
       "\n",
       "                                       processedtext  \n",
       "0  ted cruz ben carson want chariti return everi ...  \n",
       "1  latviabas drive eo creat vehicl name eo pp03 r...  \n",
       "2  alert issu rogu worker nuclear transport publi...  \n",
       "3  a short film highlight nasti thing peopl say h...  \n",
       "4  tim sherwood repli letter charli pye tuesday p...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train_df['processedtext'] = train_df['summary'].str.replace('[^\\w\\s]','') \n",
    "train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "#Lines 4 to 6\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "train_df[['character_cnt','word_counts','characters_per_word', 'spl', 'num', 'processedtext']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_features(train_df, stop = stop, stemmer = stemmer):\n",
    "    train_df['character_cnt'] = train_df['summary'].str.len()\n",
    "    train_df['word_counts'] = train_df['summary'].str.split().str.len()\n",
    "    train_df['characters_per_word'] = train_df['character_cnt']/train_df['word_counts']\n",
    "    train_df['spl'] = train_df['summary'].apply(lambda x: len([x for x in x.split() if x.startswith('@')]))\n",
    "    train_df['num'] = train_df['summary'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "    \n",
    "    train_df['processedtext'] = train_df['summary'].str.replace('[^\\w\\s]','') \n",
    "    train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "    train_df['processedtext'] = train_df['processedtext'].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 114401 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Term Frequency-Inverse Document Frequency (TF-IDF) Vector\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,1))\n",
    "\n",
    "dat_tfIdf = tfidf.fit_transform(train_df['processedtext'])\n",
    "dat_tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = train_df[\"label\"]\n",
    "training_df = train_df.drop([\"summary\", \"document\", \"label\", \"processedtext\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_df = pd.DataFrame(dat_tfIdf.toarray())\n",
    "training_df = pd.concat([training_df, td_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character_cnt</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>characters_per_word</th>\n",
       "      <th>spl</th>\n",
       "      <th>num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>833</td>\n",
       "      <td>146</td>\n",
       "      <td>5.705479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>362</td>\n",
       "      <td>65</td>\n",
       "      <td>5.569231</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>54</td>\n",
       "      <td>5.518519</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221</td>\n",
       "      <td>44</td>\n",
       "      <td>5.022727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>48</td>\n",
       "      <td>5.458333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>137</td>\n",
       "      <td>24</td>\n",
       "      <td>5.708333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>573</td>\n",
       "      <td>105</td>\n",
       "      <td>5.457143</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>4.526316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>349</td>\n",
       "      <td>70</td>\n",
       "      <td>4.985714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>317</td>\n",
       "      <td>57</td>\n",
       "      <td>5.561404</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 1005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      character_cnt  word_counts  characters_per_word  spl  num    0    1  \\\n",
       "0               833          146             5.705479    0    1  0.0  0.0   \n",
       "1               362           65             5.569231    0    3  0.0  0.0   \n",
       "2               298           54             5.518519    0    1  0.0  0.0   \n",
       "3               221           44             5.022727    0    0  0.0  0.0   \n",
       "4               262           48             5.458333    0    0  0.0  0.0   \n",
       "...             ...          ...                  ...  ...  ...  ...  ...   \n",
       "7995            137           24             5.708333    0    0  0.0  0.0   \n",
       "7996            573          105             5.457143    0    2  0.0  0.0   \n",
       "7997             86           19             4.526316    0    0  0.0  0.0   \n",
       "7998            349           70             4.985714    0    0  0.0  0.0   \n",
       "7999            317           57             5.561404    0    1  0.0  0.0   \n",
       "\n",
       "        2    3    4  ...  990  991  992  993  994       995  996  997  998  \\\n",
       "0     0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "7995  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.177304  0.0  0.0  0.0   \n",
       "7996  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "7997  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "7998  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "7999  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "      999  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "7995  0.0  \n",
       "7996  0.0  \n",
       "7997  0.0  \n",
       "7998  0.0  \n",
       "7999  0.0  \n",
       "\n",
       "[8000 rows x 1005 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Imadeddine\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "\n",
    "## Applying LogisitcRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(training_df, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3200x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48298 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = extend_features(test_df, stop = stop, stemmer = stemmer)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', stop_words= 'english', ngram_range=(1,1))\n",
    "test_tfIdf = tfidf.fit_transform(testing_df['processedtext'])\n",
    "\n",
    "testing_df = testing_df.drop([\"summary\", \"document\", \"processedtext\"], axis = 1)\n",
    "test_tfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_df = pd.DataFrame(test_tfIdf.toarray())\n",
    "testing_df = pd.concat([testing_df, td_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to a file\n",
    "with open(\"submission2_tfid1000.csv\", \"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','label'])\n",
    "    for i, row in enumerate(predictions):\n",
    "        csv_out.writerow([i, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 133155 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bag-of-words Vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bag_words = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "dat_BOW = bag_words.fit_transform(train_df['processedtext'])\n",
    "dat_BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_df = pd.DataFrame(dat_BOW.toarray())\n",
    "training_df = pd.concat([training_df, td_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Imadeddine\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Applying LogisitcRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(training_df, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "dat_BOW = bag_words.fit_transform(test_df['processedtext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_df = pd.DataFrame(dat_BOW.toarray())\n",
    "testing_df = pd.concat([testing_df, td_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(testing_df)\n",
    "\n",
    "# Write predictions to a file\n",
    "with open(\"submission2_BOW.csv\", \"w\") as pred:\n",
    "    csv_out = csv.writer(pred)\n",
    "    csv_out.writerow(['id','label'])\n",
    "    for i, row in enumerate(predictions):\n",
    "        csv_out.writerow([i, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "competition",
   "language": "python",
   "name": "competition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
